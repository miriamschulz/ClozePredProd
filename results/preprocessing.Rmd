---
title: "Data preprocessing"
author: "Miriam Schulz"
date: "2024-11-20"
output:
  html_document:
    number_sections: true
    toc: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# About

This script preprocesses the raw PC Ibex results of the Cloze prediction & production experiment.

What this script does:

- split the data into a production and a comprehension data set
- check data for completeness
- calculate by-participant and overall accuracy
- calculate by-participant and overall production RTs
- summary of demographics
- summary of post-experimental survey
- export preprocessed data as `results_preprocessed.csv`


# Read PCIbex results

Define a function to read in the raw `csv` results file as downloaded from PC Ibex:

```{r, message = FALSE}
# Preliminaries
rm(list = ls())
library(tidyverse)

read.pcibex <- function(filepath, auto.colnames=TRUE, fun.col=function(col,cols){cols[cols==col]<-paste(col,"Ibex",sep=".");return(cols)}) {
  n.cols <- max(count.fields(filepath,sep=",",quote=NULL),na.rm=TRUE)
  if (auto.colnames){
    cols <- c()
    con <- file(filepath, "r")
    while ( TRUE ) {
      line <- readLines(con, n = 1, warn=FALSE)
      if ( length(line) == 0) {
        break
      }
      m <- regmatches(line,regexec("^# (\\d+)\\. (.+)\\.$",line))[[1]]
      if (length(m) == 3) {
        index <- as.numeric(m[2])
        value <- m[3]
        if (is.function(fun.col)){
          cols <- fun.col(value,cols)
        }
        cols[index] <- value
        if (index == n.cols){
          break
        }
      }
    }
    close(con)
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=cols))
  }
  else{
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=seq(1:n.cols)))
  }
}
```

Read data frame:

```{r}
df <- read.pcibex('results_dev.csv')
# df <- read.pcibex('results.csv')
#check <- df %>% filter(UniqueID=="NULL")
df <- unique(df)
df <- df[!df$UniqueID %in% c('SomeUniqueID'), ]  # remove subject(s)
```



# Demographics

```{r}
df.demogs <- df %>%
  filter(PennElementName == 'demographics') %>% 
  select(UniqueID, Parameter, Value)

# Fix whitespace characters
df.demogs$Value <- gsub('%2C', ',', df.demogs$Value)   # commas instead of %2C
df.demogs$Value <- gsub('%0A', ' ', df.demogs$Value)   # spaces instead of %0A

# Transform to wide format
df.demogs <- df.demogs %>%
  pivot_wider(names_from = Parameter, values_from = Value)

# Make all variables factors and then age numeric
df.demogs[] <- lapply(df.demogs, tolower)
df.demogs[-2] <- lapply(df.demogs[-2], as.factor)
df.demogs$Age <- as.numeric(df.demogs$Age)

#summary(df.demogs)
#str(df.demogs)
df.demogs

# Native languages
summary(df.demogs$Native_language)

# Age
mean(df.demogs$Age)
range(df.demogs$Age)

# Gender
summary(df.demogs$Gender)

write.csv(df.demogs, "results_demographics.csv", row.names=FALSE)
```


# Post-experimental survey

```{r}
df.survey <- df %>%
  filter(PennElementName == 'postexp_survey') %>% 
  select(UniqueID, Parameter, Value)
df.survey$Value <- gsub('%2C', ',', df.survey$Value)   # commas instead of %2C
df.survey$Value <- gsub('%0A', ' ', df.survey$Value)   # spaces instead of %0A

# Transform to wide format
df.survey <- df.survey %>%
  pivot_wider(names_from = Parameter, values_from = Value)

df.survey[] <- lapply(df.survey, as.factor)
summary(df.survey$Experiment_length)
summary(df.survey$Task_difficulty)

write.csv(df.survey, "results_postexp_survey.csv", row.names=FALSE)
```



# Extract comprehension and production data

Split into a production and a comprehension data set:

```{r}
df$Value <- gsub('%2C', ',', df$Value)   # commas instead of %2C
df$Comments <- gsub('%2C', ',', df$Comments)   # commas instead of %2C

new_colnames <- c("WordPosition", "Word", "EventTime", "UniqueID",
                  "RandomOrder", "LatinList", "LatinListBinary",
                  "TaskOrder", "BlocksReversed",
                  "Block", "Task",
                  "ExpItemNum", "ExpItemType", "ExpCondition",
                  "TargetPosition", "TargetWord",
                  "TargetFreq", "TargetLength", "ContextNoun",
                  "SentenceEnd",
                  "TrialCounterGlobal", "TrialCounterTask",
                  "AnswerTime",
                  "TargetAnswer", "QuestionText", "CorrectAnswer",
                  "RunningAccuracy", "ProductionTimeout", "RecordingFilename",
                  "RT", "Sentence")

comp <- filter(df, Task == "Comprehension")
comp$Newline. <- NULL
comp <- select(comp, 10:40)
colnames(comp) <- new_colnames

prod <- filter(df, Task == "Production")
prod$Newline. <- NULL
prod <- select(prod, 10:40)
colnames(prod) <- new_colnames

```


## Comprehension accuracy

```{r}
# Extract all logged key presses
df.key <- df %>% filter(PennElementName == 'ComprehensionKey')
df.key$TrialAccuracy <- ifelse(df.key$CorrectAnswer == "true", 1, 0)

df.key.prac <- df.key %>% filter(Task == 'ExpPractice')
df.key.trials <- df.key %>% filter(Task == 'Comprehension')

# Completeness checks
table(xtabs(~ UniqueID, df.key)) # comprehension trials + comprehension practice
table(xtabs(~ UniqueID, df.key.trials))  # should equal N of comp trials with Q

# Acc for all trials
df.acc.subj <- df.key %>%
  group_by(UniqueID) %>%
  summarize(Accuracy = mean(TrialAccuracy))
df.acc.subj
round(range(df.acc.subj$Accuracy), 2)
mean(df.acc.subj$Accuracy)

# Acc only critical trials
df.acc.subj <- df.key.trials %>%
  group_by(UniqueID) %>%
  summarize(Accuracy = mean(TrialAccuracy))
df.acc.subj

round(range(df.acc.subj$Accuracy), 2)
mean(df.acc.subj$Accuracy)
```


## Completeness check

Check the item-condition and item-condition-Latin square completeness:

[TODO: this must be done for the production data too!]

```{r}
# Comprehension questions
xtabs(~ ExpCondition + ExpItemNum, df.key.trials)
xtabs(~ ExpCondition + ExpItemNum + LatinList, df.key.trials)
xtabs(~ ExpCondition + ExpItemNum + RandomOrder, df.key.trials)

# Recording filenames
length(unique(prod$RecordingFilename))
```


## Production time

```{r}
# Mean production time and task RT
prod.targets <- filter(prod, WordPosition == TargetPosition)

mean(as.numeric(prod.targets$AnswerTime))

# N of timeouts during production (> 4 sec)
summary(as.factor(prod.targets$ProductionTimeout))

# Timeouts by subject 
prod.timeouts <- xtabs(~ UniqueID + ProductionTimeout, prod.targets)#[, 2]
#TODO redo the next two lines: this doesn't work if there is no timeout in df
range(prod.timeouts[1,])
hist(prod.timeouts,
     breaks=max(prod.timeouts),
     col='steelblue')
```


## Question answer time

```{r}
# Mean production time and task RT
comp.targets <- filter(comp, WordPosition == TargetPosition)
mean(as.numeric(comp.targets$AnswerTime))
hist(comp.targets$AnswerTime,
     breaks=30,
     col='steelblue')
```


## RTs (superficial first check)

```{r}
comp.targets$RT <- as.numeric(comp.targets$RT)
prod.targets$RT <- as.numeric(prod.targets$RT)

mean(comp.targets$RT)
mean(prod.targets$RT)

comp.targets %>%
  dplyr::group_by(ExpCondition) %>%
  dplyr::summarise(mean_RT = mean(RT, na.rm = TRUE)) %>%
  print()

prod.targets %>%
  dplyr::group_by(ExpCondition) %>%
  dplyr::summarise(mean_RT = mean(RT, na.rm = TRUE)) %>%
  print()
```


# Export

```{r}
# Combine
all <- rbind(comp, prod)
all$Sentence <- gsub('%2C', ',', all$Sentence)   # commas instead of %2C

# Reorder
new_colnames <- c("EventTime", "UniqueID",
                  "RandomOrder", "LatinList", "LatinListBinary",
                  "TrialCounterGlobal", "TrialCounterTask",
                  "TaskOrder", "BlocksReversed",
                  "Block", "Task",
                  "ExpItemNum", "ExpItemType", "ExpCondition",
                  "WordPosition", "Word", "TargetWord",
                  "RT", "AnswerTime",
                  "TargetPosition", 
                  "TargetFreq", "TargetLength", "ContextNoun",
                  "TargetAnswer", "CorrectAnswer", "RunningAccuracy",
                  "QuestionText",
                  "ProductionTimeout",
                  "RecordingFilename",
                  "Sentence", "SentenceEnd")
all.export <- all[, new_colnames]

# Export
write.csv(all.export, "results_preprocessed.csv", row.names=FALSE)
```

