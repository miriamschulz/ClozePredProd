---
title: "Data preprocessing"
author: "Miriam Schulz"
date: "2024-11-20"
output:
  html_document:
    number_sections: true
    toc: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# About

This script preprocesses the raw PC Ibex results of the Cloze prediction & production experiment.

What this script does:

- split the data into a production and a comprehension data set
- summary of demographics
- summary of post-experimental survey
- check by-participant and overall accuracy
- export preprocessed data as `results_preprocessed.csv`


# Read PCIbex results

Define a function to read in the raw `csv` results file as downloaded from PC Ibex:

```{r, message = FALSE}
# Preliminaries
rm(list = ls())
library(tidyverse)
source("functions.R")
```

Read data frame:

```{r}
df <- read.pcibex('results.csv')
df <- unique(df)
# df %>% filter(Parameter == "Age") %>% select(Value)  # check that no 999 (me)
```


# Demographics

## General demographics

```{r}
df.demogs <- df %>%
  filter(PennElementName == 'demographics' | Parameter == "prolific_id") %>% 
  select(UniqueID, Parameter, Value)

# Fix whitespace characters
df.demogs$Value <- gsub('%2C', ',', df.demogs$Value)   # commas instead of %2C
df.demogs$Value <- gsub('%0A', ' ', df.demogs$Value)   # spaces instead of %0A

# Transform to wide format
df.demogs <- df.demogs %>%
  pivot_wider(names_from = Parameter, values_from = Value)

# Make all variables factors and then age numeric
df.demogs[] <- lapply(df.demogs, tolower)
df.demogs[-3] <- lapply(df.demogs[-3], as.factor)  # all columns except Age
df.demogs$Age <- as.numeric(df.demogs$Age)

# Native languages
summary(df.demogs$Native_language)

# Age
mean(df.demogs$Age)
range(df.demogs$Age)

# Gender
summary(df.demogs$Gender)
```


## Prolific completion times

```{r}
# Add the prolific IDs
demogs.prolific <- read.csv("demographics_prolific.csv", header=TRUE)
demogs.prolific <- demogs.prolific %>%
  dplyr::rename(prolific_id = Participant.id,
                Birthplace_prolific = Country.of.birth,
                Time_taken = Time.taken) %>% 
  dplyr::filter(Status != "RETURNED") %>% 
  dplyr::select(prolific_id, Birthplace_prolific, Time_taken)

df.demogs <- merge(df.demogs, demogs.prolific, by="prolific_id", all.x=TRUE)
df.demogs$Time_taken_h <- convert_to_hours(df.demogs$Time_taken)

# Calculate how the non-natives influenced the median of time taken
convert_to_hours(median(df.demogs$Time_taken))
non_natives <- c("vuqqnd", "ee49u2", "vznkz3", "3jw4ew", "ps4dv4")

# Median completion time of the non-natives:
df.demogs %>%
  filter(UniqueID %in% non_natives) %>% 
  summarise(median_time = median(Time_taken, na.rm = TRUE),
            mean_time = mean(Time_taken, na.rm = TRUE)) %>%
  mutate(median_time_hours = convert_to_hours(median_time),
         mean_time_hours = convert_to_hours(mean_time))

# Median completion time of the natives:
df.demogs %>%
  filter(!UniqueID %in% non_natives) %>% 
  summarise(median_time = median(Time_taken, na.rm = TRUE),
            mean_time = mean(Time_taken, na.rm = TRUE)) %>%
  mutate(median_time_hours = convert_to_hours(median_time),
         mean_time_hours = convert_to_hours(round(mean_time)))
```

```{r}
write.csv(df.demogs, "demographics.csv", row.names=FALSE)
```


# Post-experimental survey

```{r}
df.survey <- df %>%
  filter(PennElementName == 'postexp_survey') %>% 
  select(UniqueID, Parameter, Value)
df.survey$Value <- gsub('%2C', ',', df.survey$Value)   # commas instead of %2C
df.survey$Value <- gsub('%0A', ' ', df.survey$Value)   # spaces instead of %0A

# Transform to wide format
df.survey <- df.survey %>%
  pivot_wider(names_from = Parameter, values_from = Value)

df.survey[] <- lapply(df.survey, as.factor)
summary(df.survey$Experiment_length)
summary(df.survey$Task_difficulty)

write.csv(df.survey, "postexp_survey.csv", row.names=FALSE)
```


# Extract comprehension and production data

Split into a production and a comprehension data set:

```{r}
df$Value <- gsub('%2C', ',', df$Value)   # commas instead of %2C
df$Comments <- gsub('%2C', ',', df$Comments)   # commas instead of %2C

new_colnames <- c("WordPosition", "Word", "EventTime", "UniqueID",
                  "RandomOrder", "LatinList", "LatinListBinary",
                  "TaskOrder", "BlocksReversed",
                  "Block", "Task",
                  "ExpItemNum", "ExpItemNumOriginal",
                  "ExpItemType", "ExpCondition",
                  "TargetPosition", "TargetWord", "ClozeProb",
                  "TargetFreq", "TargetLength", "ContextNoun",
                  "SentenceEnd",
                  "TrialCounterGlobal", "TrialCounterTask",
                  "AnswerTime",
                  "TargetAnswer", "QuestionText", "CorrectAnswer",
                  "RunningAccuracy", "ProductionTimeout", "RecordingFilename",
                  "RT", "Sentence")

comp <- filter(df, Task == "Comprehension")
comp$Newline. <- NULL
comp <- select(comp, 10:42)
colnames(comp) <- new_colnames

prod <- filter(df, Task == "Production")
prod$Newline. <- NULL
prod <- select(prod, 10:42)
colnames(prod) <- new_colnames
```


## Comprehension accuracy

```{r}
# Extract all logged key presses
df.key <- df %>% filter(PennElementName == 'ComprehensionKey')
df.key$TrialAccuracy <- ifelse(df.key$CorrectAnswer == "true", 1, 0)

df.key.prac <- df.key %>% filter(Task == 'ExpPractice')
df.key.trials <- df.key %>% filter(Task == 'Comprehension')

# Completeness checks
table(xtabs(~ UniqueID, df.key)) # comprehension trials + comprehension practice
table(xtabs(~ UniqueID, df.key.trials))  # should equal N of comp trials with Q

# Acc for all trials
df.acc.subj <- df.key %>%
  group_by(UniqueID) %>%
  summarize(Accuracy = mean(TrialAccuracy))
df.acc.subj
round(range(df.acc.subj$Accuracy), 2)
mean(df.acc.subj$Accuracy)

# Acc only critical trials
df.acc.subj <- df.key.trials %>%
  group_by(UniqueID) %>%
  summarize(Accuracy = mean(TrialAccuracy))
df.acc.subj

round(range(df.acc.subj$Accuracy), 2)
mean(df.acc.subj$Accuracy)
```


## RTs (superficial first check)

```{r}
comp.targets <- filter(comp, WordPosition == TargetPosition)
comp.targets$RT <- as.numeric(comp.targets$RT)
prod.targets <- filter(prod, WordPosition == TargetPosition)
prod.targets$RT <- as.numeric(prod.targets$RT)

mean(comp.targets$RT)
mean(prod.targets$RT)

comp.targets %>%
  dplyr::group_by(ExpCondition) %>%
  dplyr::summarise(mean_RT = mean(RT, na.rm = TRUE)) %>%
  print()

prod.targets %>%
  dplyr::group_by(ExpCondition) %>%
  dplyr::summarise(mean_RT = mean(RT, na.rm = TRUE)) %>%
  print()
```


# Export

```{r}
# Combine
all <- rbind(comp, prod)
all$Sentence <- gsub('%2C', ',', all$Sentence)   # commas instead of %2C

# Reorder
new_colnames <- c("EventTime", "UniqueID",
                  "RandomOrder", "LatinList", "LatinListBinary",
                  "TrialCounterGlobal", "TrialCounterTask",
                  "TaskOrder", "BlocksReversed",
                  "Block", "Task",
                  "ExpItemNum", "ExpItemNumOriginal",
                  "ExpItemType", "ExpCondition",
                  "WordPosition", "Word", "TargetWord", "ClozeProb",
                  "RT", "AnswerTime",
                  "TargetPosition", 
                  "TargetFreq", "TargetLength", "ContextNoun",
                  "TargetAnswer", "CorrectAnswer", "RunningAccuracy",
                  "QuestionText",
                  "ProductionTimeout",
                  "RecordingFilename",
                  "Sentence", "SentenceEnd")
all.export <- all[, new_colnames]

# Export
write.csv(all.export, "results_preprocessed.csv", row.names=FALSE)
```

