---
title: "Check noun repetitions, continuations and question distributions"
author: "Miriam Schulz"
date: "2024-11-27"
output:
  html_document:
    number_sections: true
    toc: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# About

This script reads in a `csv` stimuli file for the Cloze Prediction & Production experiment as well as the fillers file and performs multiple checks over the stimuli:

- Overlap of the nouns within and across both sets (there should be no overlap between nouns used in the fillers and context/target item nouns, and overlap within the items will be mitigated using Latin square lists and distribution of stimuli into experimental blocks)
- Mean target noun length and frequency by condition
- Spillover words ("continuations"): should be short and mainly closed class
- Filler conditions: should show a distribution into 50/50 short and structure variation fillers, and 50/50 expected and unexpected fillers (but not evenly crossed into both subcategories, because it is difficult to construct natural short unexpected production fillers)
- Comprehension questions
- Context sentence length preceding the cloze word
- Latin square distribution
- Block distribution


# Duplicate checks

## Check if there are duplicate nouns in the items (context and target nouns)

In a first step, the data is read in and the chosen items (indicated by a $1$ in the column `picked`) are subsetted:

```{r, message=FALSE}
library("tidyverse")
rm(list = ls())
```

```{r cars}
# Read in the data
dat <- read.csv("stim_exp.csv", header=TRUE)

# Filter the data set for the chosen candidate items
dat <- filter(dat, candidates=="1")

# Print items that do not occur exactly twice
subset(as.data.frame(xtabs(~ item_id + candidates, dat)), Freq != 2)
```

Write a function that will check if a word appears more than once,
either in the context nouns, in the target nouns, or across context and target nouns:

```{r}
check_overlap <- function(data, col1, col2) {
  # Check duplicates within each column
  duplicates_col1_table <- sort(table(data[[col1]])[table(data[[col1]]) > 2], decreasing=TRUE) / 2
  duplicates_col1 <- names(duplicates_col1_table)
  print("Duplicates within the context nouns:")
  print(duplicates_col1_table)
  
  duplicates_col2_table <- sort(table(data[[col2]])[table(data[[col2]]) > 1], decreasing=TRUE)
  duplicates_col2 <- names(duplicates_col2_table)
  print("Duplicates in the target nouns:")
  print(duplicates_col2_table)
  
  # Check for words appearing in both columns
  #duplicates_all_table <- (table(data[[col1]]) / 2) + (table(data[[col2]]))
  table1 <- table(data[[col1]]) / 2
  table2 <- table(data[[col2]])
  all_names <- union(names(table1), names(table2))
  aligned_table1 <- table1[all_names]
  aligned_table2 <- table2[all_names]
  aligned_table1[is.na(aligned_table1)] <- 0
  aligned_table2[is.na(aligned_table2)] <- 0
  duplicates_all_table <- sort(aligned_table1 + aligned_table2, decreasing=TRUE)
  duplicates_all_table <- duplicates_all_table[!is.na(names(duplicates_all_table))]

  print("Duplicates across both context and target nouns:")
  #print(length(duplicates_all_table))
  #print(sum(duplicates_all_table)) # 80 context nouns + N=4 overlapping nouns
  print(duplicates_all_table)
  
  common_words <- intersect(data[[col1]], data[[col2]])
  
  # Return results as a list
  return(list(
    duplicates_in_col1 = duplicates_col1,
    duplicates_in_col2 = duplicates_col2,
    common_words = common_words
  ))
}
```

Print the duplicate nouns:

```{r}
overlap <- check_overlap(dat, "W3", "target")
overlap
```


## Detect if a noun is still free to use in the fillers

Check if a noun has been used as context or target noun in the items, or if it is still free to use as a noun in the fillers:

```{r}
# Create a set of all nouns used as context or target noun in the items:
noun_set <- sort(unique(c(dat$W3, dat$target)))
# Check if a specific word is present in this set (TRUE/FALSE):
"mother" %in% noun_set
"work" %in% noun_set
```


## Check the fillers for overlap with the items

Once the fillers have been written, we should check again if there are any nouns in the final filler set that occur as context/target noun in the items.

Read in the file `fillers.csv` and write a function to check for overlap with the item noun set:

```{r}
# Read in the fillers
fillers <- read.csv("fillers.csv", header=TRUE)
#fillers <- filter(fillers, Chosen != "No")

# Merge the context sentence and target columns into a single vector
filler_sentences <- c(fillers$Sentence, fillers$Target)

# Split the sentences into individual words
filler_sentences <- gsub("[[:punct:]]", "", filler_sentences)
filler_words <- unique(tolower(unlist(strsplit(filler_sentences, "\\s+"))))
filler_words <- filler_words[filler_words != ""]  # remove empty string
#head(filler_words)
```

```{r}
check_filler_overlap <- function(item_nouns, filler_words) {
  for (w in filler_words) {
    if (w %in% item_nouns) {
      print(w)
    }
  }
}

check_filler_overlap(noun_set, filler_words)
```


# Mean Target Length and Cloze probability by Condition

```{r}
dat %>% 
  group_by(cond) %>% 
  summarize(mean(length))
```


```{r}
dat %>% 
  group_by(cond) %>% 
  summarize(mean(cloze_prob))
```


# Continuations

## Check the continuations (spillover regions)

How often is each continuation (spillover word 1 + spillover word 2) used?

```{r}
spill <- select(dat, Spill1, Spill2)

# Check both spillover words as combination
spill$Spillover <- paste(spill$Spill1, spill$Spill2, sep = " ")
spillover_table <- data.frame(sort(xtabs(~ Spillover, spill) / 2, decreasing = TRUE))
write.csv(spillover_table, "spillover_counts.csv", row.names=FALSE)

# Check first spillover word only
spill1_table <- data.frame(sort(xtabs(~ Spill1, spill) / 2, decreasing = TRUE))
write.csv(spill1_table, "spillover_counts_spill1.csv", row.names=FALSE)
```


# Filler conditions

```{r}
# Filler conditions
xtabs(~ FillerType, fillers)

# Unexpected fillers
xtabs(~ Unexpected, filter(fillers, FillerType %in% c("Short", "StructureVariation")))

# Unexpectedness in both filler conditions (but not equally often,
# because there are fewer options for short unexpected fillers)
xtabs(~ FillerType + Unexpected, filter(fillers, FillerType %in% c("Short", "StructureVariation")))
prop.table(xtabs(~ FillerType + Unexpected, filter(fillers, FillerType %in% c("Short", "StructureVariation"))), margin=1)
```


# Comprehension questions

## Items

```{r}
dat$Sentence <- paste(dat$W1, dat$W2, dat$W3, dat$W4, dat$W5, 
                      dat$LastWord, dat$target,
                      dat$Spill1, dat$Spill2, dat$Continuation, dat$End,
                      sep = " ")
# Remove trailing whitespaces
dat <- dat %>% 
  mutate(Sentence = gsub("\\s{2,}", " ", Sentence))

questions <- select(dat, item_id, Sentence, HasQuestion, Question, Answer, QuestionAbout)

# Check that 1/3 of all items have a question:
length(unique(questions$item_id))  # N all items
xtabs(~ HasQuestion, questions) /2  # N items with question
prop.table(xtabs(~ HasQuestion, questions))  # % items with question

# Subset
questions <- filter(questions, HasQuestion == "Yes")

# Check that there is a question about each sentence position equally often
xtabs(~ QuestionAbout, questions) / 2

# Check that each sentence position has a true vs. false answer equally often
xtabs(~ Answer + QuestionAbout, questions) / 2
```

Inspect the actual questions:

```{r}
questions <- arrange(questions, QuestionAbout, Answer, item_id)
questions$HasQuestion <- NULL
#questions$Answer <- ifelse(questions$Answer == "D", "False", "True")
write.csv(questions, "comprehension_questions.csv", row.names=FALSE)
```


## Fillers

```{r}
fillers <- filter(fillers, !(FillerType %in% c("prac_comprehension", "prac_production")))

questions_fillers <- select(fillers, Filler_id, FillerType, Unexpected, Sentence, Target,
                            HasQuestion, Question, Answer, QuestionAbout)

# Check that 1/3 of all items have a question:
length(unique(questions_fillers$Filler_id))  # N all fillers
xtabs(~ HasQuestion, questions_fillers)  # N fillers with question
prop.table(xtabs(~ HasQuestion, questions_fillers))  # % fillers with question

# Subset
questions_fillers <- filter(questions_fillers, HasQuestion == "Yes")

# Check that each filler type has a question ~ equally often
xtabs(~ FillerType, questions_fillers)

# Check that there are ~ equally many questions per expected/unespectedness
xtabs(~ Unexpected, questions_fillers)

# Less important, but avoid any strong imbalance here:
xtabs(~ FillerType + Unexpected, questions_fillers)

# Check that there is a question about each sentence position ~ equally often
xtabs(~ QuestionAbout, questions_fillers)

# Check that each answer occurs equally often:
xtabs(~ Answer, questions_fillers)
xtabs(~ Answer + Unexpected, questions_fillers)
xtabs(~ Answer + FillerType, questions_fillers)
xtabs(~ Answer + QuestionAbout, questions_fillers)
```


# Pre-cloze context sentence length

## Items

```{r}
dat$Sentence <- paste(dat$W1, dat$W2, dat$W3, dat$W4, dat$W5, 
                      dat$LastWord, dat$target,
                      dat$Spill1, dat$Spill2, dat$Continuation,# dat$End,
                      sep = " ")
# Remove trailing whitespaces
dat <- dat %>% 
  mutate(Sentence = gsub("\\s{2,}", " ", Sentence))

range(sapply(str_split(dat$Sentence, " "), length))
mean(sapply(str_split(dat$Sentence, " "), length))
```

## Fillers

```{r}
#range(sapply(str_split(fillers$Sentence, " "), length))
#mean(sapply(str_split(fillers$Sentence, " "), length))
fillers$ContextLength <- sapply(str_split(fillers$Sentence, " "), length)
range(fillers$ContextLength)
mean(fillers$ContextLength)
```

Split into short vs. structure variation fillers:

```{r}
short <- filter(fillers, FillerType == "Short")
range(short$ContextLength)
mean(short$ContextLength)

variation <- filter(fillers, FillerType == "StructureVariation")
range(variation$ContextLength)
mean(variation$ContextLength)
```


# Latin square distribution

Some targets appear multiple times in the stimuli.

Targets that appear 2x in the stimuli must be put in separate lists.

The three targets that appear 3x each must be put in different lists but will inevitably occur twice in one list ('game', 'house', 'book').

```{r}
# Check that no manually specified latin constraints are violated:
summary(dat$Latin_constraints == dat$Latin_list)  # must all be TRUE or NA

# The key constraints may specify an unequal distribution
xtabs(~ cond + Latin_constraints, dat)

# However, the full Latin square must be fully balanced:
xtabs(~ cond + Latin_list, dat)

# Each item must appear only once in each list, and not 0x in one and 2x in the
# other, so the range should be from 1 to 1:
range(xtabs(~ item_id + cond, dat))

# Each target must appear only once per list, with the exception of 
# game, house and book:
xtabs(~ target + Latin_list, dat)
target_xtabs <- as.data.frame(xtabs(~ target + Latin_list, dat))
target_xtabs[order(target_xtabs$Freq, target_xtabs$Latin_list), ] %>%
  filter(Freq > 1)
```


# Division into blocks

## Items

Each list is divided into 4 blocks: one comprehension block and one production block, each divided in two to allow for a small break.

The distribution of items into blocks is used to keep some items apart, based on the following constraints:

- duplicate targets within a list must be kept maximally far apart (blocks 1 and 4)
- targets that also appear as a context noun must appear first (block 1) and be kept maximally far apart from the item with the same context noun (block 4)
- context nouns that appear several times must be placed maximally apart, into different blocks (if a noun appears 2x, blocks 1+4; if it appears 4x (max, 'girl'), once in each block)

The definition of these hard constrains was done manually on the Google docs.

The constraints will not be balanced:

```{r}
xtabs(~ Latin_list + Block_constraints, dat)
# xtabs(~ Block_constraints + cond + Latin_list, dat)
# xtabs(~ Block_constraints + HasQuestion + Latin_list, dat)
# xtabs(~ Block_constraints + Answer + Latin_list, dat)

# Check that no manually specified block constraints are violated:
summary(dat$Block_constraints == dat$Block)  # must all be TRUE or NA
```

But the final block distribution should be balanced with respect to the conditions and N questions in each block:

```{r}
xtabs(~ Latin_list + Block, dat, addNA=T)
xtabs(~ Block + cond + Latin_list, dat)

# Must contain 13-14 in first column and 6-7 in second column:
xtabs(~ Block + HasQuestion, dat) / 2

# Must contain 3-4 everywhere:
xtabs(~ Block + Answer, dat) / 2

# Should contain 1-2 everywhere:
xtabs(~ Block + QuestionAbout, dat) / 2

# Should contain 3-4 everywhere:
xtabs(~ cond + Block + Latin_list, filter(dat, HasQuestion == "Yes"))
```

Also check that the division of target and context nouns into blocks worked (in each Latin list, this should range from 0x to 1x max for each block):

```{r}
# Targets (must range from 0 to 1): 
range(xtabs(~ target + Block + Latin_list, dat))

# Context nouns (must range from 0 to 1):
range(xtabs(~ W3 + Block + Latin_list, dat))
```


## Fillers

Check the distribution of items AND fillers in each block.

Fillers are used to counterbalance: 

- The N of questions per block
- The N of each answer (TRUE/FALSE) per block
- The QuestionAbout per block: ask approximately equally ofen about each sentence part.
  
Also, there should be roughtly the same N of expected/unexpected and short/variation fillers in each block.

The distribution of fillers into blocks was done manually on the fillers Google doc.

```{r}
xtabs(~ Block, fillers)

# Pre-format the fillers to merge
fillers <- rename(fillers, item_id = Filler_id)
fillers$cond <- ifelse(fillers$Unexpected == "yes",
                       paste(fillers$FillerType, "Unexp", sep="_"),
                       paste(fillers$FillerType, "Exp", sep="_"))
fillers$QuestionAbout <- ifelse(fillers$QuestionAbout == "Adjective/Adverb",
                                "Adjective", fillers$QuestionAbout)

# Will show merged conditions (not an equal distribution)
xtabs(~ cond, fillers)

# Must show 6s or 4s in every column:
xtabs(~ Block + cond, fillers)

# Duplicate for Latin lists
fillers <- rbind(fillers, fillers)
fillers$Latin_list <- rep(1:2, each = nrow(fillers)/2)

# Merge fillers and items
all <- rbind(select(dat, item_id, cond, Latin_list, Block, HasQuestion, QuestionAbout, Answer),
             select(fillers, item_id, cond, Latin_list, Block, HasQuestion, QuestionAbout, Answer))

# Check final distribution
xtabs(~ Block + Latin_list, all)
xtabs(~ cond + Latin_list, all)
xtabs(~ Block + cond + Latin_list, all)

# Now these should all be balanced (in the columns):
xtabs(~ Block + HasQuestion, all) / 2  # contain 26-27 and 13-14
xtabs(~ Block + Answer, all) / 2  # contain 6s and 7s
xtabs(~ Block + QuestionAbout, all) / 2 # contain 2s and 3s

# Check in depth: cond + block + question + list; 
# these should be balanced row-wise:
xtabs(~ cond + Block + Latin_list, all)
xtabs(~ cond + Block + Latin_list, filter(all, HasQuestion == "Yes"))
xtabs(~ cond + Block + Latin_list, filter(all, HasQuestion == ""))
```

